import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
from html_module import section, callout, line_break, title
import lightgbm as lgb
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error


st.set_page_config(
    page_title="Modeling | ì‚¬ìë™ì‚°",  # ì „ì²´ íƒ€ì´í‹€
    page_icon="ğŸ¦",  # ì•„ì´ì½˜
)
title('Modeling')


# ë°ì´í„°ì…‹ ë¡œë“œ í•¨ìˆ˜
@st.cache
def data_load():
    X_train = pd.read_csv('data/X_train.csv')
    y_train = pd.read_csv('data/y_train.csv')
    X_test = pd.read_csv('data/X_test.csv')
    y_test = pd.read_csv('data/y_test.csv')
    return X_train, X_test, y_train, y_test


# íŒŒë¼ë¯¸í„° ì„¸íŒ… í•¨ìˆ˜
def set_params(learning_rate, seed, metric, max_depth, n_estimators, subsample):
    params = {
        'learning_rate': learning_rate,
        'objective': 'regression',
        'metric': metric,
        'seed': seed,
        'max_depth': max_depth,
        'n_estimators': n_estimators,
        'subsample': subsample
    }
    return params


# ë°ì´í„°ì…‹ ë¡œë“œ í•¨ìˆ˜
# @st.cache
def dataset_load(X_train, X_test, y_train, y_test):
    train_dataset = lgb.Dataset(X_train, y_train)
    test_dataset = lgb.Dataset(X_test, y_test)
    return train_dataset, test_dataset


# lgb í•™ìŠµ í•¨ìˆ˜
def train_lgb(train_dataset, test_dataset, params):
    lgb_model = lgb.train(
        params, train_dataset, 10000, test_dataset,
        verbose_eval=500, early_stopping_rounds=100
    )
    return lgb_model


# ì†ì‹¤í•¨ìˆ˜ ë¦¬í„´ í•¨ìˆ˜
def set_loss(y_test, y_predict):
    mae = mean_absolute_error(y_test, y_predict)
    mse = mean_squared_error(y_test, y_predict)
    rmse = mse ** 0.5
    rmsle = mean_squared_log_error(y_test, y_predict) ** 0.5
    return mae, mse, rmse, rmsle


# ì†ì‹¤í•¨ìˆ˜ ì¶œë ¥ í•¨ìˆ˜
def print_loss(loss):
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("MAE", round(loss[0], 3))
    col2.metric("MSE", int(loss[1]))
    col3.metric("RMSE", round(loss[2], 3))
    col4.metric("RMSLE", round(loss[3], 5))


# ëª¨ë¸ íšŒê·€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° í•¨ìˆ˜
def print_re_graph(y_test, y_predict):
    fig, ax = plt.subplots()
    ax.scatter(y_test, y_predict)
    ax.plot([1121.87, 63770.43], [1121.87, 63770.43], '--r')
    plt.xlabel("True Charges")
    plt.ylabel("Predicted Charges")
    plt.tight_layout()
    st.pyplot(fig)


section('ê°œìš”')
callout(['LightGBM ì‚¬ìš©'])
line_break()

section('íŒŒë¼ë¯¸í„° ì„¤ì •í•˜ì—¬ ëª¨ë¸ë§í•˜ê¸°', 300)
col1, col2 = st.columns(2)
with col1:
    # metric = st.radio('metric', ['mae', 'mse', 'rmse'])
    metric = st.selectbox('metric', ('mae', 'mse', 'rmse'))
    line_break()
    learning_rate = float(st.slider('learning rate', 0.0, 1.0, 0.3))
    line_break()
    max_depth = int(st.slider('max depth', 1, 10, 5))

with col2:
    seed = int(st.slider('seed', 0, 100, 42))
    line_break()
    n_estimators = int(st.select_slider(
        'n_estimator', options=list(range(100, 501, 100))))
    line_break()
    subsample = float(st.slider('subsample', 0.0, 1.0, 0.7))


line_break()
model_btn = st.button('ëª¨ë¸ë§ Start')
line_break()
X_train, X_test, y_train, y_test = data_load()
train_dataset, test_dataset = dataset_load(X_train, X_test, y_train, y_test)

if model_btn:
    params = set_params(learning_rate, seed, metric,
                        max_depth, n_estimators, subsample)

    # my_bar = st.progress(0)
    lgb_model_state = st.text('2ë¶„ì€ ì¡±íˆ ë„˜ê²Œ ê±¸ë¦½ë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš” Loading...')
    lgb_model = train_lgb(train_dataset, test_dataset, params)
    # for percent_complete in range(100):
    # time.sleep(0.1)
    # my_bar.progress(percent_complete + 1)
    lgb_model_state.success("ëª¨ë¸ë§ ì™„ë£Œ")

    y_predict = lgb_model.predict(X_test)
    loss = set_loss(y_test, y_predict)
    print_loss(loss)
    with st.expander("ì†ì‹¤í•¨ìˆ˜ ê·¸ë˜í”„ ë³´ê¸° ğŸ”"):
        print_re_graph(y_test, y_predict)
